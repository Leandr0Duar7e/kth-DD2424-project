\documentclass{article}

% Pass options to natbib BEFORE loading neurips_2024
\PassOptionsToPackage{numbers,compress}{natbib}

% Use NeurIPS style
\usepackage[final]{neurips_2024}

% Additional packages
\usepackage[utf8]{inputenc}
\bibliographystyle{unsrtnat}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}

\title{Comparing ResNet and Vision Transformers: Supervised vs Semi-Supervised Learning for Pet Breed Classification}

\author{%
  Francesco Olivieri \\
  KTH Royal Institute of Technology \\
  \texttt{olivieri@kth.se} \\
  \And
  Inês Mesquita \\
  KTH Royal Institute of Technology \\
  \texttt{inesm@kth.se} \\
  \And
  Leandro Duarte \\
  KTH Royal Institute of Technology \\
  \texttt{ldr0@kth.se} \\
}

\begin{document}

\maketitle

\begin{abstract}
% Brief overview of the project, approach, and key results
% Should be no more than 300 words
\end{abstract}

\section{Introduction}
The task of image classification, that is, assigning a label to an image from a predefined set of categories, has a wide-range of applications, such as in computer vision. However, training models with high accuracies from scratch often necessitates vast amounts of labeled data, which can be expensive and time-consuming to acquire. Transfer learning offers a powerful tool to mitigate this challenge by leveraging knowledge from models pre-trained on large-scale datasets and adapting them to new, specific tasks with significantly less data. Our project explores this concept through the specific problem of pet breed classification using the Oxford-IIT Pet Dataset, a task that serves as an excellent benchmark for evaluating fine-tuning strategies.

Our report focuses on a comparative analysis of two architectures. We evaluate ResNet50, a Convolutional Neural Network against Vision Transformer (ViT), specifically the Hugging Face implementation. Furthermore, recognizing that the scarcity of labeled data can be posed as a problem, we extend our analysis to the domain of semi-supervided learning (SSL). SSL techniques are particularly important as they aim to harness the information present in abundant unlabeled data alongside limited labeled examples. In this project, we specifically implement pseudo-labeling and evaluate the performance of both ResNet50 and ViT as the proportion of labeled training data is progressively reduced. This allows us to assess their robustness and the efficacy of SSL in data-constrained regimes. Ultimately, our findings aim to contribute to a better understanding of how these distinct architectures and learning strategies perform when adapting to specialized visual recognition tasks.


% Describe the problem and its importance
% Briefly describe what you did and give an overview of results
% Why is transfer learning important?
% Why compare ResNet and ViT?
% Why study semi-supervised learning?


\section{Related Work}
% Discuss published work related to:
% 1. Transfer learning with CNNs and Vision Transformers
% 2. Semi-supervised learning techniques
% 3. Pet breed classification or similar fine-grained classification tasks


\section{Data}
The project utilizes the Oxford-IIIT Pet Dataset \\cite{Parkhi2012}, a benchmark for fine-grained visual classification. It contains 7,349 images of 37 pet breeds, with around 200 images per class. The dataset features significant variations in scale, pose, and lighting. Annotations include breed, head Region of Interest (ROI), and pixel-level trimap segmentations.

For all experiments, images are resized to 224x224 pixels and normalized. Data augmentation techniques such as random horizontal flips and rotations are applied in specific experiments. Vision Transformer (ViT) models utilize specific preprocessing steps via the Hugging Face AutoImageProcessor. The dataset is consistently split into training, validation, and test sets. For the semi-supervised learning (SSL) experiments, the proportion of labeled data in the training set was systematically reduced, with the remainder treated as unlabeled data to assess model performance under data scarcity.

Given that the Oxford-IIIT Pet Dataset is a standard benchmark, various methods have been evaluated on it. State-of-the-art results are often achieved by Transformer-based models; for instance, fine-tuned Vision Transformers have reported accuracies around 94\% \cite{HFNorburayViTPets}. Other competitive approaches include specialized transformer architectures like OmniVec2 \cite{Srivastava2024OmniVec2}. Zero-shot learning with models like CLIP has also demonstrated strong performance, achieving up to 88\% accuracy without dataset-specific fine-tuning \cite{HFMuellje3ViTPets}.



\section{Methods}
% Describe your approaches in detail:
Adam optimizer.


% ResNet architecture and configuration
% Vision Transformer architecture and configuration
\subsubsection{ResNet50}
The model structure of Residual Networks (ResNet)  [\cite{he2015deepresiduallearningimage}], more specifically the one of ResNet50, begins with an input layer that accepts images of size 224 × 224 with three color channels (RGB). This is followed by a convolutional layer with 64 filters of size 7 × 7 (stride 2),  which extracts low-level features from the input images. The output is passed through batch normalization to normalize the activations, a ReLU activation function is then used to introduce non-linearity, and a 3x3 max pooling with stride 2 to reduce dimensions and introduce translation invariance. The core of ResNet consists of four stages, each consisting of multiple residual blocks. Each block includes three convolutional layers, each followed by batch normalization and ReLU activation. These blocks incorporate skip connections, which add the input of the block to its output, useful to prevent the vanishing gradient problem and enabling deeper networks. The architecture ends with global average pooling and a dense layer with sigmoid activation for multi-label classification.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{resnet_arch.png}
    \caption{ResNet50 Architecture}
    \label{fig:resnet_architecture}
\end{figure}

For our experiments, we used a pre-trained ResNet50 model(on ImageNet), and we changed the fully connected layer to match our needs. Either for binary classification (cat vs dogs) or multi-class classification (identifying breeds of cats and dogs, 37 different breeds).

For our experiments, we used a pre-trained ResNet-50 model, originally trained on the ImageNet dataset, which contains over one million images across 1,000 categories. Leveraging transfer learning allowed us to benefit from the rich, generalized feature representations learned by the network on a large-scale dataset, especially useful given the smaller size of our own dataset.

To adapt the model to our specific classification tasks, we replaced the original final fully connected layer (originally outputting 1,000 logits) with a new dense layer tailored to the desired number of output classes. In the binary classification task (e.g., distinguishing between cats and dogs), the final layer was modified to output a single neuron with a sigmoid activation function. For the multi-class classification task (e.g., identifying 37 different breeds of cats and dogs), we used a dense layer with 37 output neurons and a softmax activation function to model the probability distribution over the classes.

We fine-tuned the entire model or, in some experiments, froze the earlier layers and only trained the modified classifier head. This allowed us to evaluate the benefit of task-specific tuning versus using fixed pre-trained features. During training, we used categorical cross-entropy for the multi-class case and binary cross-entropy for the binary case, optimizing with the Adam optimizer and applying early stopping to avoid overfitting.

Additionally, data augmentation techniques such as random horizontal flips, rotations, and color jittering were applied to increase robustness and help generalize better to unseen examples. All images were resized to 224 × 224 to match the input requirements of ResNet-50.

\subsection{ViT}
% Fine-tuning strategies for ResNet
% Fine-tuning strategies for Vision Transformer
% Hyperparameters and optimization details


\subsection{Semi-Supervised Learning}
% Description of the semi-supervised learning technique(s) used
% Implementation details
For our semi-supervised learning experiments, the pseudo-labeling technique was implemented \cite{lee2013pseudo}. The core idea behind  pseudo-labeling is to leverage the model's own predictions on unlabeled data to augment the training set. The model is first trained on the available limited labeled data. This model is then used to predict labels for the unlabeled data pool. The model is then retrained on this combined dataset of original labels and high-confidence pseudo-labels, ideally improving its generalization. 

It will now be discussed how we implemented the pseudo-labeling on this project in specific. For each scenario with reduced labeled data, given the best configuration of each model, either ResNet50 or ViT, was tested with 50\%, 10\% and 1\% of the full training set. Then the model in question was trained exclusively on this limited labeled subset. This establishes a baseline supervised. Then, the aforementioned model was used to make predictions on the remaining unlabeled portion of the training dataset. For each unlabeled image, the prediction was accepted as a pseudo-label for that image. The pseudo-labeled images are then added to the original labeled images as the new training set. The model was then retrained using this augmented dataset. The model parameters obtained from the initial supervised training on the limited labeled subset were then further fine-tuned using the augmented dataset, which combined the original ground-truth labels and the newly generated pseudo-labels. This approach of continuing the training process with the inclusion of pseudo-labels aligns with the methodology described in the foundational work on pseudo-labeling by Lee (2013)\cite{lee2013pseudo}. The performance of this retrained model was then evaluated on the held-out test set.  

The process was apllied independently for both ResNEt50 and ViT architectures across the different percentagees of labeled data explored. 

\subsection{Codebase}
The project was implemented in Python, leveraging libraries such as PyTorch, Hugging Face Transformers, and Scikit-learn. The codebase is structured modularly, with key components including `src/main.py` for experiment orchestration via a command-line interface, `src/dataset.py` for data loading and preprocessing (including specific handling for ResNet50 and ViT, and semi-supervised splits), model definitions within `src/models/`, `src/trainer.py` for managing the training loops (including pseudo-labeling logic and gradual unfreezing for ResNet), and `src/evaluation.py` for performance assessment and results visualization. A detailed overview of the system architecture, data processing pipeline, and individual module functionalities is available in the project's DeepWiki documentation \cite{OurProjectDeepWiki}. The complete source code is publicly available on GitHub \cite{OurProjectRepoGithub}.

% Add a figure environment here if you create the diagram
% \begin{figure}[h]
%     \centering
%     % \includegraphics[width=0.8\textwidth]{path/to/your/architecture_diagram.png}
%     \caption{High-level system architecture diagram.}
%     \label{fig:system_architecture}
% \end{figure}

\section{Experiments}
% Detailed description of experiments and results
We replaced the last layer of the network for binary classification and fine-tuned only this latter, while the backbone was frozen.

\subsection{Fully-Supervised Learning}
% Results from dog vs cat classification
Using all the labeled data.

\subsubsection{Binary Classification}
For this task, the aim is tho classify whether the animal in the image is a dog or a cat.

\subsubsubsection{ResNet50}
  The network was then trained for 2 epochs and a final accuracy on a test set was recorded at 99.72\% using learning rate 0.01. 


\subsubsection{Multi-Class Classification}


\subsection{Semi-Supervised Learning}
% Results from dog vs cat classification

\subsubsection{Binary Classification}

\subsubsection{Multi-Class Classification}



\subsection{Ablation Studies}
% Effect of different components of your approach
% Learning rate strategies, regularization, etc.
\subsubsection{ResNet50}

\subsubsection{ViT}

\section{Conclusion}
% Summary of key findings
% Limitations of the study
% Suggestions for future work


\section{Broader Impacts}
% Discuss potential positive societal impacts
% Discuss potential negative societal impacts
% Consider fairness, privacy, security implications


\section*{References}
% List all references


\appendix
\section{Additional Experiments}
% Place for any additional results that didn't fit in the main paper


\section{Implementation Details}
% More detailed information about implementations
% Hyperparameter settings, training configurations

\bibliography{references}
\end{document}